{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad42ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal, stats\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import re\n",
    "from neurodsp.timefrequency import compute_wavelet_transform\n",
    "from BCI2kReader import BCI2kReader as b2k\n",
    "import os\n",
    "import mne\n",
    "from tabulate import tabulate\n",
    "import IPython\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42270c4d",
   "metadata": {},
   "source": [
    "This script is the interactive/dev version to turn the bci states into a csv comprable to the csvs I get from prolifc in order to compare their behavior.\n",
    "\n",
    "The basic plan is to create and index to get a timestep of 50ms, loop through all of my_states, pull values for each variable of interest into a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70826c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/brooke/knight_server/remote/'\n",
    "eeg_fi = base_dir + 'WashU/data/PacmanTask/BJH016/PacmanTask/ECOGS001R01.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f761919f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceDecimation\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"SourceMin\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"SourceMax\"\n"
     ]
    }
   ],
   "source": [
    "with b2k.BCI2kReader(eeg_fi) as data: #opens a stream to the dat file\n",
    "    my_signals = data.signals\n",
    "    my_states = data.states\n",
    "    my_params = data.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "1b7590b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names =  ['Subject',\n",
    "              'Trial',\n",
    "               'Time', \n",
    "               'GhostLocation',\n",
    "               'UserLocation',\n",
    "               'Direction',\n",
    "               'Biscuit1',\n",
    "               'Biscuit2',\n",
    "               'Biscuit3',\n",
    "               'Biscuit4',\n",
    "               'Biscuit5',\n",
    "               'Attack',\n",
    "               'Chase',\n",
    "               'Eaten',\n",
    "               'Score',\n",
    "               'Lives',\n",
    "               'TrialType']\n",
    "\n",
    "cleaned_game_data = pd.DataFrame(columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc5170bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_500 = my_params['SamplingRate'] *.05\n",
    "task_length = len(my_states['Trial_on_off'][0])\n",
    "flips_per_task = int(task_length / samples_per_500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0856e",
   "metadata": {},
   "source": [
    "Okay, so every 50ms, corresponds to a csv with `nrows = 59019`, which is *much* larger than the size of the csvs from prolific data. However, the ITIs in the prolific data are not sampled at 50ms, and the task was run twice for this subject. So together, I think this makes sense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "803bdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(flips_per_task):\n",
    "    sample = int(range(task_length)[iter] * samples_per_500)\n",
    "    cleaned_game_data.loc[iter] = [\"BJH016\", my_states['Trial_on_off'][0][sample], sample,\n",
    "              my_states['GhostLocation'][0][sample], my_states['UserLocation'][0][sample], my_states['Direction'][0][sample],  \n",
    "              my_states['Biscuit1'][0][sample], my_states['Biscuit2'][0][sample], my_states['Biscuit3'][0][sample],\n",
    "              my_states['Biscuit4'][0][sample], my_states['Biscuit5'][0][sample], my_states['Attack'][0][sample],\n",
    "              my_states['Chase'][0][sample], my_states['Eaten'][0][sample], my_states['Score'][0][sample],\n",
    "              my_states['Lives'][0][sample], my_states['TrialType'][0][sample]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b178816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to beginning of trial\n",
    "first_trial = cleaned_game_data.Trial.eq(1).idxmax() - 3 # start a couple of time points ahead of first trial\n",
    "last_row = cleaned_game_data.shape[0]\n",
    "cleaned_game_data = cleaned_game_data.loc[first_trial:last_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4094e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trial count\n",
    "cleaned_game_data.reset_index(inplace=True, drop = True)\n",
    "last_row = cleaned_game_data.shape[0]\n",
    "end_index = False\n",
    "begin_index = False\n",
    "# cleaned_game_data = cleaned_game_data.rename(columns={'Trial': 'Trial_on_off'})  \n",
    "for idx in range(4, last_row):\n",
    "    if cleaned_game_data.Trial_on_off[idx] == 0 and cleaned_game_data.Trial_on_off[idx - 1] == 1:\n",
    "        begin_index = idx + 1\n",
    "    if cleaned_game_data.Trial_on_off[idx] == 1 and cleaned_game_data.Trial_on_off[idx - 1] == 0:\n",
    "        end_index = idx - 2\n",
    "    if end_index is not False:\n",
    "        bad_df = cleaned_game_data.index.isin(np.arange(begin_index, end_index))\n",
    "        cleaned_game_data = cleaned_game_data[~bad_df]\n",
    "        end_index = False\n",
    "        begin_index = False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a3c5951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now there are three zeros separating every trial, so lets count the trials!\n",
    "cleaned_game_data.reset_index(inplace=True, drop = True)\n",
    "last_row = cleaned_game_data.shape[0]\n",
    "trial_counter = 1\n",
    "cleaned_game_data['Trial'] = 0\n",
    "for idx in range(4, last_row):\n",
    "    cleaned_game_data.loc[idx, 'Trial'] = trial_counter\n",
    "    if cleaned_game_data.Trial_on_off[idx] == 0 and cleaned_game_data.Trial_on_off[idx - 1] == 1:\n",
    "        trial_counter = trial_counter + 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "0118fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_game_data.to_csv('./bci_converted_behave_BJH016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25949d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ieeg_analysis] *",
   "language": "python",
   "name": "conda-env-ieeg_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
